{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4664b3b",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ada7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from interpret import show\n",
    "from interpret.glassbox import ExplainableBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8990d",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb3f0b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "DATA_PATH_TRAIN = \"DATA/learn.csv\"\n",
    "DATA_PATH_TEST = \"DATA/test.csv\"\n",
    "\n",
    "FEAT_GLM = [\n",
    "    \"VehPowerGLM\", \"VehAgeGLM\", \"DrivAgeGLM\", \"BonusMalusGLM\",\n",
    "    \"VehBrand\", \"VehGas\", \"DensityGLM\", \"Region\", \"AreaGLM\"\n",
    "]\n",
    "\n",
    "FEAT_EBM = [\n",
    "    \"VehPower\", \"VehAge\", \"DrivAge\", \"BonusMalus\",\n",
    "    \"VehBrand\", \"VehGas\", \"Density\", \"Region\", \"AreaGLM\"\n",
    "]\n",
    "\n",
    "EBM_FEATURE_TYPES = [\n",
    "    \"continuous\", \"continuous\", \"continuous\", \"continuous\",\n",
    "    \"nominal\", \"nominal\", \"continuous\", \"nominal\", \"continuous\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821eeb27",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f654b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def edr_poisson(y_true, y_pred, nul_pred, weights):\n",
    "    \"\"\"Compute Explained Deviance Reductions based on Poisson deviance.\"\"\"\n",
    "    nul_dev = mean_poisson_deviance(y_true=y_true, y_pred=nul_pred, sample_weight=weights)\n",
    "    mod_dev = mean_poisson_deviance(y_true=y_true, y_pred=y_pred, sample_weight=weights)\n",
    "    return 1 - mod_dev / nul_dev\n",
    "\n",
    "def get_prediction_breakdown(ebm, X, feature_names=None):\n",
    "    \"\"\"Calculates contribution of each feature to the final prediction.\"\"\"\n",
    "    if feature_names is None:\n",
    "        feature_names = ebm.feature_names if hasattr(ebm, \"feature_names\") else [f\"F{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "    X_array = X.values if isinstance(X, pd.DataFrame) else np.array(X)\n",
    "    sample_scores, breakdowns = [], []\n",
    "\n",
    "    for sample_idx, sample in enumerate(X_array):\n",
    "        intercept_val = float(ebm.intercept_) if isinstance(ebm.intercept_, (int, float, np.number)) else float(ebm.intercept_[0])\n",
    "        score = intercept_val\n",
    "        breakdown = {\"sample_idx\": sample_idx, \"intercept\": intercept_val, \"features\": {}}\n",
    "\n",
    "        for term_idx, features in enumerate(ebm.term_features_):\n",
    "            term_name = \" x \".join([feature_names[f] for f in features])\n",
    "            tensor_index = []\n",
    "            feature_values = {}\n",
    "\n",
    "            for f_idx in features:\n",
    "                val = sample[f_idx]\n",
    "                feature_values[feature_names[f_idx]] = val\n",
    "                bins = ebm.bins_[f_idx][min(len(ebm.bins_[f_idx]) - 1, len(features) - 1)]\n",
    "\n",
    "                is_missing = val is None or (isinstance(val, float) and np.isnan(val)) or (isinstance(val, str) and val.strip() == \"\")\n",
    "                if is_missing:\n",
    "                    bin_idx = 0\n",
    "                elif isinstance(bins, dict):\n",
    "                    v_str = str(int(val)) if isinstance(val, (int, float)) and val == int(val) else str(val)\n",
    "                    bin_idx = bins.get(v_str, len(bins) + 1)\n",
    "                else:\n",
    "                    bin_idx = np.digitize(float(val), bins, right=False) + 1\n",
    "                tensor_index.append(bin_idx)\n",
    "\n",
    "            local_score = ebm.term_scores_[term_idx][tuple(tensor_index)]\n",
    "            score += local_score\n",
    "            breakdown[\"features\"][term_name] = {\"value\": feature_values, \"contribution\": float(local_score)}\n",
    "\n",
    "        breakdown[\"total_score\"] = float(score)\n",
    "        sample_scores.append(score)\n",
    "        breakdowns.append(breakdown)\n",
    "\n",
    "    predictions = np.exp(np.array(sample_scores))\n",
    "    return predictions, breakdowns\n",
    "\n",
    "def get_ebm_coefficients(ebm, feature_names=None):\n",
    "    \"\"\"Extracts all bins and their corresponding scores from an EBM model.\"\"\"\n",
    "    if feature_names is None:\n",
    "        feature_names = ebm.feature_names\n",
    "    \n",
    "    coeffs = []\n",
    "    for term_idx, features in enumerate(ebm.term_features_):\n",
    "        term_name = feature_names[features[0]] if len(features) == 1 else \" x \".join([feature_names[f] for f in features])\n",
    "        scores = ebm.term_scores_[term_idx]\n",
    "        \n",
    "        if len(features) == 1:\n",
    "            f_idx = features[0]\n",
    "            bins = ebm.bins_[f_idx][0]\n",
    "            if isinstance(bins, dict):\n",
    "                for cat, b_idx in bins.items():\n",
    "                    coeffs.append({\"term\": term_name, \"bin_value\": cat, \"score\": float(scores[b_idx])})\n",
    "                coeffs.append({\"term\": term_name, \"bin_value\": \"MISSING\", \"score\": float(scores[0])})\n",
    "            else:\n",
    "                for b_idx in range(len(scores)):\n",
    "                    label = \"MISSING\" if b_idx == 0 else (f\"<= {bins[0]}\" if b_idx == 1 else (f\"> {bins[-1]}\" if b_idx > len(bins) else \"BIN\"))\n",
    "                    coeffs.append({\"term\": term_name, \"bin_value\": label, \"score\": float(scores[b_idx])})\n",
    "        else:\n",
    "            coeffs.append({\"term\": term_name, \"bin_value\": \"Interaction Tensor\", \"score\": np.mean(np.abs(scores))})\n",
    "            \n",
    "    return pd.DataFrame(coeffs)\n",
    "\n",
    "def double_lift_fixed(y_m1, y_m2, y_act, weight=None, p_tile=10, model_names=(\"M1\", \"M2\")):\n",
    "    \"\"\"Generates a Double Lift Chart comparing two models against actuals.\"\"\"\n",
    "    sns.set()\n",
    "    df = pd.DataFrame({model_names[0]: y_m1, model_names[1]: y_m2, \"actual\": y_act})\n",
    "    df[\"weight\"] = weight if weight is not None else 1\n",
    "    df[\"Ratio\"] = df[model_names[0]] / df[model_names[1]]\n",
    "    df = df.sort_values(\"Ratio\")\n",
    "    df[\"cum_w\"] = df[\"weight\"].cumsum()\n",
    "    df[\"p_tile\"] = pd.qcut(df[\"cum_w\"], p_tile, labels=False, duplicates=\"drop\") + 1\n",
    "    \n",
    "    agg = df.groupby(\"p_tile\").agg({model_names[0]: \"mean\", model_names[1]: \"mean\", \"actual\": \"mean\"}).reset_index()\n",
    "    melted = agg.melt(\"p_tile\", var_name=\"Model\", value_name=\"Value\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=melted, x=\"p_tile\", y=\"Value\", hue=\"Model\", marker=\"o\")\n",
    "    plt.title(\"Double Lift Chart\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    return agg, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa09e50",
   "metadata": {},
   "source": [
    "Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38262b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH_TRAIN)\n",
    "test = pd.read_csv(DATA_PATH_TEST)\n",
    "\n",
    "train_expo, test_expo = train[\"Exposure\"], test[\"Exposure\"]\n",
    "log_expo_train, log_expo_test = np.log(train_expo), np.log(test_expo)\n",
    "\n",
    "y_train, y_test = train[\"ClaimNb\"], test[\"ClaimNb\"]\n",
    "X_train_ebm, X_test_ebm = train[FEAT_EBM], test[FEAT_EBM]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535391f",
   "metadata": {},
   "source": [
    "GLM Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula1 = \"ClaimNb ~ C(VehPowerGLM) + C(VehAgeGLM) + C(DrivAgeGLM) + BonusMalusGLM + C(VehBrand) + C(VehGas) + DensityGLM + C(Region) + C(AreaGLM)\"\n",
    "glm1 = sm.GLM.from_formula(formula1, data=train, family=sm.families.Poisson(), offset=log_expo_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693058a",
   "metadata": {},
   "source": [
    "GLM Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a380fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula3 = \"\"\"ClaimNb ~ C(VehPowerGLM) + C(VehAgeGLM) + np.log(DrivAge) + I(DrivAge**3) + I(DrivAge**4) + \n",
    "              BonusMalusGLM * DrivAge + BonusMalusGLM * I(DrivAge**2) + C(VehBrand) + C(VehGas) + \n",
    "              DensityGLM + C(Region) + AreaGLM\"\"\"\n",
    "glm3 = smf.glm(formula3, data=train, family=sm.families.Poisson(), offset=log_expo_train).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3801b",
   "metadata": {},
   "source": [
    "EBM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d7268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_std = ExplainableBoostingRegressor(feature_names=FEAT_EBM, feature_types=EBM_FEATURE_TYPES, objective=\"poisson_deviance\", n_jobs=1)\n",
    "ebm_std.fit(X_train_ebm, y_train, init_score=log_expo_train)\n",
    "\n",
    "ebm_best = ExplainableBoostingRegressor(feature_names=FEAT_EBM, feature_types=EBM_FEATURE_TYPES, objective=\"poisson_deviance\", interactions=1, n_jobs=1)\n",
    "ebm_best.fit(X_train_ebm, y_train, init_score=log_expo_train)\n",
    "\n",
    "ebm_best2 = ExplainableBoostingRegressor(feature_names=FEAT_EBM, feature_types=EBM_FEATURE_TYPES, objective=\"poisson_deviance\", interactions=3, n_jobs=1)\n",
    "ebm_best2.fit(X_train_ebm, y_train, init_score=log_expo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852ebdc",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict = {\n",
    "    \"GLM_Base\": glm1.predict(test, offset=log_expo_test),\n",
    "    \"GLM_Complex\": glm3.predict(test, offset=log_expo_test),\n",
    "    \"EBM_Std\": ebm_std.predict(X_test_ebm, init_score=log_expo_test),\n",
    "    \"EBM_Best\": ebm_best.predict(X_test_ebm, init_score=log_expo_test),\n",
    "    \"EBM_Best2\": ebm_best2.predict(X_test_ebm, init_score=log_expo_test)\n",
    "}\n",
    "\n",
    "for name, p in preds_dict.items():\n",
    "    dev = mean_poisson_deviance(y_test, p)\n",
    "    print(f\"{name} Test Deviance: {dev:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1917cc71",
   "metadata": {},
   "source": [
    "Visualization & Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_global = ebm_best2.explain_global()\n",
    "show(ebm_global)\n",
    "\n",
    "double_lift_fixed(preds_dict[\"EBM_Std\"], preds_dict[\"EBM_Best2\"], y_test, p_tile=20, model_names=(\"EBM_std\", \"EBM_best\"))\n",
    "plt.show()\n",
    "\n",
    "X_sample = test[FEAT_EBM].head(10)\n",
    "local_preds, breakdowns = get_prediction_breakdown(ebm_best, X_sample, feature_names=FEAT_EBM)\n",
    "print(\"\\nSample 0 Breakdown:\", breakdowns[0])\n",
    "\n",
    "df_coef = get_ebm_coefficients(ebm_best, FEAT_EBM)\n",
    "df_coef.to_excel(\"ebm_coefficients.xlsx\", index=False)\n",
    "print(\"\\nCoefficients exported to ebm_coefficients.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
